{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94f2e5f-d166-467b-bcf6-2b9b2a5094a3",
   "metadata": {},
   "source": [
    "# SVHN: Evaluation Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611fcd9-f9fe-4e4d-b8df-3fc2bc563fbf",
   "metadata": {},
   "source": [
    "## Imports and SVHN loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c41803-b032-42dd-a35e-4b1174955429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook will use PyTorch Device: CUDA\n"
     ]
    }
   ],
   "source": [
    "# Imports all the module paths\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# Requirements for running everything\n",
    "import torch\n",
    "\n",
    "# File containing all the required training methods\n",
    "import defences.svhn_library as svhn_library\n",
    "\n",
    "# For testing\n",
    "import utils.clean_test as clean_test\n",
    "\n",
    "# Contains the data loadders\n",
    "import utils.dataloaders as dataloaders\n",
    "\n",
    "# For printing outcomes\n",
    "# import utils.printing as printing\n",
    "\n",
    "# Example printing, but I removed it to simplify results\n",
    "# for epsilon in epsilons:\n",
    "#     printing.print_attack(\n",
    "#         model,\n",
    "#         testSetLoader,\n",
    "#         \"FGSM\",\n",
    "#         attacks[\"FGSM\"],\n",
    "#         epsilon=epsilon,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8be8e6-665e-4650-ab07-02c581f17bf7",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a0d6d5-0b5a-4395-8a73-d2a2dad36307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../../datasets/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: ../../datasets/SVHN/extra_32x32.mat\n",
      "Using downloaded and verified file: ../../datasets/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: ../../datasets/SVHN/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"../../datasets/SVHN\"\n",
    "\n",
    "trainSetLoader, _, testSetLoader = dataloaders.get_SVHN_data_loaders(\n",
    "    DATA_ROOT,\n",
    "    trainSetSize=63257,\n",
    "    validationSetSize=0,\n",
    "    batchSize=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68d722-0a8e-4d8f-9dc4-143d4ee59a77",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb8a5e8-0b93-430c-984f-0a8d219076bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_LOAD_ROOT = \"../../data/svhn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa4d6b-b40f-4ac6-b2fe-6c30490b5359",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the Attacks For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f068383-33f2-43e7-a1b9-62d65ed623ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A possible attacks array (for nice printing):\n",
    "# Some attacks use a helper library\n",
    "import torchattacks\n",
    "\n",
    "import attacks.fgsm as fgsm\n",
    "import attacks.ifgsm as ifgsm\n",
    "import attacks.pgd as pgd\n",
    "import utils.attacking as attacking\n",
    "\n",
    "attacks = {}\n",
    "\n",
    "attacks[\"FGSM\"] = fgsm.fgsm_attack\n",
    "attacks[\"I-FGSM\"] = ifgsm.ifgsm_attack\n",
    "attacks[\"PGD\"] = pgd.pgd_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c169cf-f7e4-4924-9530-8d980942f29f",
   "metadata": {},
   "source": [
    "## Accuracy of a Standard Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36a3a9d-41a8-4f5f-9423-37ddb8633d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found already trained model...\n",
      "... loaded!\n"
     ]
    }
   ],
   "source": [
    "standard_model = svhn_library.standard_training(\n",
    "    trainSetLoader,\n",
    "    load_if_available=True,\n",
    "    load_path=SAVE_LOAD_ROOT + \"/svhn_standard\",\n",
    "    long_training=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba47e60-e928-461d-9dc1-1506f81c3950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4dfd02fbb84f869540e1642f8a9c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 95.09%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "clean_test.test_trained_model(standard_model, testSetLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "227c0ac5-f496-485f-a29f-fe8b43393334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(standard_model, SAVE_LOAD_ROOT + \"/svhn_standard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa78cf50-1a48-4f6a-98dd-452b18801152",
   "metadata": {},
   "source": [
    "## Training Phase: Jacobian Regularizared PG+$CW_2$ Adversarially Trained Model (i.e. 2-Attack Adversarial Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "342c43f1-e23a-4e5f-aeb1-5d93b28eee32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found already trained model...\n",
      "... loaded!\n"
     ]
    }
   ],
   "source": [
    "# Pass none since if there is no attack function specified, will use CW2 instead\n",
    "framework_model = svhn_library.framework_training(\n",
    "    trainSetLoader,\n",
    "    attack_function1=attacks[\"PGD\"],\n",
    "    attack_function2=None,\n",
    "    load_if_available=True,\n",
    "    load_path=SAVE_LOAD_ROOT + \"/svhn_framework\",\n",
    "    epsilon1=(8 / 255),\n",
    "    alpha=(2 / 255),\n",
    "    iterations=7,\n",
    "    steps=15,\n",
    "    c=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70724216-599c-406a-a2fc-3dcadd13c77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7235ded0b3cf47f9a97703ba0b9de644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 89.66%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "clean_test.test_trained_model(framework_model, testSetLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddf5af3e-c7de-469a-8080-d837e8483d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(framework_model, SAVE_LOAD_ROOT + \"/svhn_framework\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ad446b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77191e",
   "metadata": {},
   "source": [
    "#### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ac4132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model under FGSM Attack using epsilon = 0, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c362596182149df80a2532a09b3fa2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 89.66%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.01, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc46e4eaace242a3b5f1947876955911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 77.32%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.05, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4482b706a447feb09bae19befc7a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 45.26%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.1, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0671ca42ce44a35921915c6d9c2ed94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 34.98%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.2, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4028f271094ef19805fe96805ed3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 34.04%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.35, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775acce50cb94a73902dfbf2146313ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 34.3%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.55, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71bf1173740f403695229f32c5344e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 36.07%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 0.75, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe0aa0bafd342e9acd20ab877839614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 37.21%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under FGSM Attack using epsilon = 1, alpha = None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55107a4fcc842ad8d2594ae01ef0347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FGSM Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 37.47%\n",
      "------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Several values to use for the epsilons\n",
    "epsilons = [0, 0.01, 0.05, 0.1, 0.2, 0.35, 0.55, 0.75, 1]\n",
    "\n",
    "# Run test for each epsilon\n",
    "for epsilon in epsilons:\n",
    "    attacking.attack_model(\n",
    "        framework_model,\n",
    "        testSetLoader,\n",
    "        \"FGSM\",\n",
    "        attacks[\"FGSM\"],\n",
    "        epsilon=epsilon,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257872d4",
   "metadata": {},
   "source": [
    "#### PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90ff0784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model under PGD Attack using epsilon = 0, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85dd422bdd814a3a8a5d4556d11bbc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 89.66%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.01, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794737bf2480492d8b927728012593bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 75.0%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.05, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f916e7eaf1c84ca7914c06332cbbc00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 36.5%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.1, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d2f7fbd0fd419e9d4111db99d17f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 29.21%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.2, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867587b04a854f2b8c1a7f154e6d9635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 17.13%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.35, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d202e8fa155f46e8840fa829eb195102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 5.64%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.55, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f8dfc1b40d4b96a12d062c088ec426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 0.85%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 0.75, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c7b508381e4e048cca229431ec7a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 0.06%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under PGD Attack using epsilon = 1, alpha = 0.00784313725490196...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd63d1e3c3e44922ae96585dba54a231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 0.01%\n",
      "------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Several values to use for the epsilons\n",
    "epsilons = [0, 0.01, 0.05, 0.1, 0.2, 0.35, 0.55, 0.75, 1]\n",
    "\n",
    "for epsilon in epsilons:\n",
    "    attacking.attack_model(\n",
    "        framework_model,\n",
    "        testSetLoader,\n",
    "        \"PGD\",\n",
    "        attacks[\"PGD\"],\n",
    "        epsilon=epsilon,\n",
    "        alpha=(2 / 255),\n",
    "        iterations=7,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ded23",
   "metadata": {},
   "source": [
    "#### $CW_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25e5d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034526efdad2455ca0cb47047208afd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 79.51%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5544ff706d4a0ba2090d93e4063866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 52.91%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34bf5d8676646b89da79da8c4cf627a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 51.29%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c663c55b7e4c77bd6fc70d8a08b118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 50.95%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e896439b9ee1496d85807af4ddde69e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 47.42%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2016a3a4d54fb2b6f1c6af9035e932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 38.91%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d776a41eb17745389d6dcb0bfdd8bc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 36.26%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f466485efad942e8973c19bd561e1ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 35.13%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef48ce2f682c402ca59d8c03fe343394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 36.94%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5408014184045ed8839b6cc7fac98d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 23.94%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e0a8bc05e2494e92e61c52292ce00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 19.18%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36c70669cd34c1ab0c1596131af97fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 16.82%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d069ca2741ee49dd904659af3c3c64df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 31.94%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0941af406941478f111594eb59d7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 15.14%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431a008829d14f8bb09bf9cdf12aba12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 8.25%\n",
      "------------------------------------\n",
      "\n",
      "Testing the model under CW Attack...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44140d5c3f046e6b14c8729b2d879e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW Attack Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 5.05%\n",
      "------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step_nums = [15, 30, 50, 100]\n",
    "cs = [0.05, 0.1, 0.3, 1]\n",
    "\n",
    "for c in cs:\n",
    "    for step_num in step_nums:\n",
    "        cw_attack = torchattacks.CW(framework_model, c=c, steps=step_num)\n",
    "        attacks[\"CW\"] = cw_attack\n",
    "\n",
    "        attacking.attack_model(\n",
    "        framework_model,\n",
    "        testSetLoader,\n",
    "        \"CW\",\n",
    "        attacks[\"CW\"],\n",
    "        library=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaaa37f-65ba-4580-9f38-962037e3202b",
   "metadata": {},
   "source": [
    "## Detection Phase: PCA-based Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "979620e4-dedc-4860-afcc-1b9f30931cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook will use PyTorch Device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.notebook import tnrange, tqdm\n",
    "\n",
    "# Define the `device` PyTorch will be running on, please hope it is CUDA\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Notebook will use PyTorch Device: \" + device.upper())\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Copy the SVHN data and then fit using PCA\n",
    "# First convert to numpy arrays (and make it float)\n",
    "numpyTrainingData = trainSetLoader.dataset.data.astype(\"float32\")\n",
    "# Note you also need to reshape the input data for your sanity\n",
    "reshapedNumpyTrainingData = numpyTrainingData.reshape(\n",
    "    (len(numpyTrainingData), 32 * 32 * 3)\n",
    ")\n",
    "\n",
    "# Then perform PCA on training data to get principal components\n",
    "# Note it should reflect dimension of image, i.e. 28 * 28\n",
    "pca = PCA(n_components=32 * 32 * 3).fit(reshapedNumpyTrainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5ca70-48a8-432e-b3b5-bed94e993462",
   "metadata": {},
   "source": [
    "#### Benign Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0dd37bd-c9c8-483f-9bdc-9616af662286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "# Now on clean data check if there are any adversarial samples\n",
    "numpyTestData = testSetLoader.dataset.data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e3924-7e1b-4c87-b7b2-671f16cebbf3",
   "metadata": {},
   "source": [
    "#### FGSM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80512d0e-be22-4e83-87e8-44a9f1b3723c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f098d58f3a242c5821bcb111278af1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "9217\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = fgsm.fgsm_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        framework_model,\n",
    "        loss_function,\n",
    "        epsilon=0.75,\n",
    "        alpha=None,\n",
    "        scale=True,\n",
    "        iterations=None,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c102d2-3fc7-48ad-9820-fde13466959e",
   "metadata": {},
   "source": [
    "#### PGD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "885fdb00-e4c8-437d-904e-845f0307b6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b97aff6798d4737964c72c20609d666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "9988\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = pgd.pgd_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        framework_model,\n",
    "        loss_function,\n",
    "        epsilon=0.75,\n",
    "        alpha=(2 / 255),\n",
    "        iterations=7,\n",
    "        scale=True,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0ffcdef-d96f-44a3-a2fe-e6754e964b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b01dd838d32492eb563841e4f78fef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "9875\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = pgd.pgd_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        framework_model,\n",
    "        loss_function,\n",
    "        epsilon=0.001,\n",
    "        alpha=(2 / 255),\n",
    "        iterations=7,\n",
    "        scale=True,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcfcf257-1332-4ab4-89b9-3393b957a7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9ba26db4fe48d49c8f53fb40aa56a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "9960\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = pgd.pgd_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        framework_model,\n",
    "        loss_function,\n",
    "        epsilon=0.85,\n",
    "        alpha=(2 / 255),\n",
    "        iterations=20,\n",
    "        scale=True,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d03e9-087f-4ed8-91a0-011e83a6f7e3",
   "metadata": {},
   "source": [
    "#### $CW_{2}$ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "344a37fd-40a4-40c2-bfdd-9b2f9257054c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3a57cb9c764077ad7971ef831b6dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "9926\n"
     ]
    }
   ],
   "source": [
    "cw_attack = torchattacks.CW(framework_model, c=1, steps=100)\n",
    "\n",
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = cw_attack(\n",
    "        images,\n",
    "        labels,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 20\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaaa37f-65ba-4580-9f38-962037e3202b",
   "metadata": {},
   "source": [
    "## Detection Phase: Mahalanobis-based Detection\n",
    "\n",
    "Please see in the **defences/mahalanobis_detector/** folder how to run the Mahalanobis-based Detection component, as it has a separate procedure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
