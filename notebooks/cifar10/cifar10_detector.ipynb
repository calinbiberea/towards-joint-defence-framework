{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf6b41ca-5f07-4710-baae-24a1ed8dda14",
   "metadata": {},
   "source": [
    "# CIFAR-10: Adversarial Robustness Analysis of Detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079b34ed-646a-4a6d-9804-456031bbbe7f",
   "metadata": {},
   "source": [
    "## Imports and CIFAR-10 loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc6f794-8ded-4bca-bd88-62c136ee6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports all the module paths\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tnrange, tqdm\n",
    "\n",
    "# For testing\n",
    "import utils.clean_test as clean_test\n",
    "\n",
    "# Contains the data loadders\n",
    "import utils.dataloaders as dataloaders\n",
    "\n",
    "# For printing outcomes\n",
    "# import utils.printing as printing\n",
    "\n",
    "# Example printing, but I removed it to simplify results\n",
    "# for epsilon in epsilons:\n",
    "#     printing.print_attack(\n",
    "#         model,\n",
    "#         testSetLoader,\n",
    "#         \"FGSM\",\n",
    "#         attacks[\"FGSM\"],\n",
    "#         epsilon=epsilon,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b26f2046-3c5c-435a-a11d-bbeb41de6db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook will use PyTorch Device: CUDA\n"
     ]
    }
   ],
   "source": [
    "# Define the `device` PyTorch will be running on, please hope it is CUDA\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Notebook will use PyTorch Device: \" + device.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fee513-bdec-474f-9a4b-9c7a7321b7f2",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3cf35b0-a90d-4e04-b2d8-57e52f553b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"../../datasets/CIFAR10/\"\n",
    "\n",
    "trainSetLoader, _, testSetLoader = dataloaders.get_CIFAR10_data_loaders(\n",
    "    DATA_ROOT,\n",
    "    trainSetSize=50000,\n",
    "    validationSetSize=0,\n",
    "    batchSize=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460fcff-4216-45da-b876-a6a4ec9e8941",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Attacks and Their Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7493eab6-d768-4f30-ac44-5c80f33fbef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A possible attacks array (for nice printing):\n",
    "# Some attacks use a helper library\n",
    "import torchattacks\n",
    "\n",
    "import attacks.fgsm as fgsm\n",
    "import attacks.ifgsm as ifgsm\n",
    "import attacks.pgd as pgd\n",
    "import utils.attacking as attacking\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "attacks = {}\n",
    "\n",
    "attacks[\"FGSM\"] = fgsm.fgsm_attack\n",
    "attacks[\"I-FGSM\"] = ifgsm.ifgsm_attack\n",
    "attacks[\"PGD\"] = pgd.pgd_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae51ea-8cf4-4b1a-9c38-949b04e81d60",
   "metadata": {},
   "source": [
    "## Load two models (standard and FGSM trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df83148d-a234-464f-90ee-e383f11349f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loaded!\n"
     ]
    }
   ],
   "source": [
    "standard_model = torch.load(\"../../data/cifar10/cifar10_standard\")\n",
    "standard_model.eval()\n",
    "\n",
    "pgd_model = torch.load(\"../../data/cifar10/cifar10_pgd\")\n",
    "pgd_model.eval()\n",
    "\n",
    "print(\"...loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "006d2a5c-2df4-4da7-963f-a035d62ddf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76301b4e87fc48e6a1ad352d7967edc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 95.25%\n",
      "Testing the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6726d4d11d5246e680742a37ea6c5399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Accuracy: 84.68%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the two models\n",
    "clean_test.test_trained_model(standard_model, testSetLoader)\n",
    "clean_test.test_trained_model(pgd_model, testSetLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48235d0-c883-4e64-bb29-9deef17c259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A possible attacks array (for nice printing):\n",
    "# Some attacks use a helper library\n",
    "import torchattacks\n",
    "\n",
    "import attacks.fgsm as fgsm\n",
    "import attacks.ifgsm as ifgsm\n",
    "import attacks.pgd as pgd\n",
    "import utils.attacking as attacking\n",
    "\n",
    "attacks = {}\n",
    "\n",
    "attacks[\"FGSM\"] = fgsm.fgsm_attack\n",
    "attacks[\"I-FGSM\"] = ifgsm.ifgsm_attack\n",
    "attacks[\"PGD\"] = pgd.pgd_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc582167-ff7d-4693-b8e8-8e9c6acec531",
   "metadata": {},
   "source": [
    "## Classification score approach for detecting adversarial example in deep neural network\n",
    "https://link.springer.com/article/10.1007/s11042-020-09167-z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acc1f2c-cbdc-428c-b694-12fa7dae2c77",
   "metadata": {},
   "source": [
    "## Standard Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c84132e-c96e-4244-905e-b2821500c2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb994441c2934964a5efe201b73f7b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Rejected 22, Accepted 9978, Accuracy: 95.37983563840449%\n"
     ]
    }
   ],
   "source": [
    "# Here you decide on the threshold for the clean dataset\n",
    "threshold = 0.1\n",
    "\n",
    "# Rejected\n",
    "accepted = 0\n",
    "rejected = 0\n",
    "correct = 0\n",
    "\n",
    "# Use a pretty progress bar to show updates\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(images)\n",
    "\n",
    "    # The highest class represents the chosen class (input, k, dimension)\n",
    "    _, preds = torch.topk(logits, 2, 1)\n",
    "\n",
    "    # Check each image and see if it is adversarial\n",
    "    for index in range(len(images)):\n",
    "        max_index = preds[index][0]\n",
    "        sec_index = preds[index][1]\n",
    "\n",
    "        diff = logits[index][max_index] - logits[index][sec_index]\n",
    "\n",
    "        if diff < threshold:\n",
    "            rejected += 1\n",
    "        else:\n",
    "            accepted += 1\n",
    "            correct += max_index == labels[index]\n",
    "\n",
    "\n",
    "print(\n",
    "    \"... done! Rejected {}, Accepted {}, Accuracy: {}%\".format(\n",
    "        rejected, accepted, float(correct) * 100 / accepted\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "765a66e2-7bab-488a-a68d-14a1e4e9a46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a934027949c74cb5bc40c4bc581f9a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Rejected 438, Accepted 9562, Accuracy: 8.920727881196402%\n"
     ]
    }
   ],
   "source": [
    "# Here you decide on the threshold for the clean dataset\n",
    "threshold = 0.4\n",
    "\n",
    "# Rejected\n",
    "accepted = 0\n",
    "rejected = 0\n",
    "correct = 0\n",
    "\n",
    "# Use a pretty progress bar to show updates\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = fgsm.fgsm_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        standard_model,\n",
    "        loss_function,\n",
    "        epsilon=0.35,\n",
    "        alpha=None,\n",
    "        scale=True,\n",
    "        iterations=None,\n",
    "    )\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(perturbed_images)\n",
    "\n",
    "    # The highest class represents the chosen class (input, k, dimension)\n",
    "    _, preds = torch.topk(logits, 2, 1)\n",
    "\n",
    "    # Check each image and see if it is adversarial\n",
    "    for index in range(len(images)):\n",
    "        max_index = preds[index][0]\n",
    "        sec_index = preds[index][1]\n",
    "\n",
    "        diff = logits[index][max_index] - logits[index][sec_index]\n",
    "\n",
    "        if diff < threshold:\n",
    "            rejected += 1\n",
    "        else:\n",
    "            accepted += 1\n",
    "            correct += max_index == labels[index]\n",
    "\n",
    "print(\n",
    "    \"... done! Rejected {}, Accepted {}, Accuracy: {}%\".format(\n",
    "        rejected, accepted, float(correct) * 100 / accepted\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d6601d-214d-4c83-8bcf-135c595b8c86",
   "metadata": {},
   "source": [
    "## PGD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e0858f2-f772-4e25-b4c1-233dfda4d50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ca55fab5b44797bbdf171c56640514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Rejected 95, Accepted 9905, Accuracy: 85.14891468955074%\n"
     ]
    }
   ],
   "source": [
    "# Here you decide on the threshold for the clean dataset\n",
    "threshold = 0.1\n",
    "\n",
    "# Rejected\n",
    "accepted = 0\n",
    "rejected = 0\n",
    "correct = 0\n",
    "\n",
    "# Use a pretty progress bar to show updates\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        logits = pgd_model(images)\n",
    "\n",
    "    # The highest class represents the chosen class (input, k, dimension)\n",
    "    _, preds = torch.topk(logits, 2, 1)\n",
    "\n",
    "    # Check each image and see if it is adversarial\n",
    "    for index in range(len(images)):\n",
    "        max_index = preds[index][0]\n",
    "        sec_index = preds[index][1]\n",
    "\n",
    "        diff = logits[index][max_index] - logits[index][sec_index]\n",
    "\n",
    "        if diff < threshold:\n",
    "            rejected += 1\n",
    "        else:\n",
    "            accepted += 1\n",
    "            correct += max_index == labels[index]\n",
    "\n",
    "print(\n",
    "    \"... done! Rejected {}, Accepted {}, Accuracy: {}%\".format(\n",
    "        rejected, accepted, float(correct) * 100 / accepted\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "905ad550-203c-4487-9f73-a7ace56f077a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044d176bc9ba451d8c368cfe98200650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done! Rejected 815, Accepted 9185, Accuracy: 22.939575394665216%\n"
     ]
    }
   ],
   "source": [
    "# Here you decide on the threshold for the clean dataset\n",
    "threshold = 0.25\n",
    "\n",
    "# Rejected\n",
    "accepted = 0\n",
    "rejected = 0\n",
    "correct = 0\n",
    "\n",
    "# Use a pretty progress bar to show updates\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = fgsm.fgsm_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        pgd_model,\n",
    "        loss_function,\n",
    "        epsilon=0.35,\n",
    "        alpha=None,\n",
    "        scale=True,\n",
    "        iterations=None,\n",
    "    )\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        logits = pgd_model(perturbed_images)\n",
    "\n",
    "    # The highest class represents the chosen class (input, k, dimension)\n",
    "    _, preds = torch.topk(logits, 2, 1)\n",
    "\n",
    "    # Check each image and see if it is adversarial\n",
    "    for index in range(len(images)):\n",
    "        max_index = preds[index][0]\n",
    "        sec_index = preds[index][1]\n",
    "\n",
    "        diff = logits[index][max_index] - logits[index][sec_index]\n",
    "\n",
    "        if diff < threshold:\n",
    "            rejected += 1\n",
    "        else:\n",
    "            accepted += 1\n",
    "            correct += max_index == labels[index]\n",
    "\n",
    "print(\n",
    "    \"... done! Rejected {}, Accepted {}, Accuracy: {}%\".format(\n",
    "        rejected, accepted, float(correct) * 100 / accepted\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cfa049-b9cb-44e8-af81-700e533acaa7",
   "metadata": {},
   "source": [
    "## PCA-based Detection with a Standard Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1adb1c17-c296-41f3-9e32-5eac4f30c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Copy the data and then fit using PCA\n",
    "# First convert to numpy arrays (and make it float)\n",
    "numpyTrainingData = trainSetLoader.dataset.data.astype(\"float32\")\n",
    "# Note you also need to reshape the input data for your sanity\n",
    "reshapedNumpyTrainingData = numpyTrainingData.reshape(\n",
    "    (len(numpyTrainingData), 32 * 32 * 3)\n",
    ")\n",
    "\n",
    "# Then perform PCA on training data to get principal components\n",
    "# Note it should reflect dimension of image, i.e. 28 * 28\n",
    "pca = PCA(n_components=32 * 32 * 3).fit(reshapedNumpyTrainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7c5735-61c9-49b9-bc4d-d53374c96baf",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44e38927-deec-4d27-b0f9-e83bc0dd621e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Now on clean data check if there are any adversarial samples\n",
    "numpyTestData = testSetLoader.dataset.data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb0d68-5011-44fa-85cc-01ead99210ec",
   "metadata": {},
   "source": [
    "#### FGSM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99ab8767-6731-4205-ac3d-9165ea7bb6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19f2e56bbf14fc28509eb6b2d91aab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "9412\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = fgsm.fgsm_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        pgd_model,\n",
    "        loss_function,\n",
    "        epsilon=0.75,\n",
    "        alpha=None,\n",
    "        scale=True,\n",
    "        iterations=None,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "890c3d8b-57d2-445c-ba2e-a71e30e975c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4151d936820543faaac685060d4eda55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "9002\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = fgsm.fgsm_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        pgd_model,\n",
    "        loss_function,\n",
    "        epsilon=0.01,\n",
    "        alpha=None,\n",
    "        scale=True,\n",
    "        iterations=None,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4032e4c9-897a-4fb5-beb3-b2614c1b4d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2205d18404f400d9106fa3695d9ee44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "8943\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = fgsm.fgsm_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        pgd_model,\n",
    "        loss_function,\n",
    "        epsilon=0.25,\n",
    "        alpha=None,\n",
    "        scale=True,\n",
    "        iterations=None,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f84c37-f77b-46a9-a6d2-8c44b172968f",
   "metadata": {},
   "source": [
    "#### $CW_{2}$ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "086f419e-6a65-4bc3-895b-c2d3d155ffc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fde7bd878a4d2fb1c8349aafcdad50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "9271\n"
     ]
    }
   ],
   "source": [
    "cw_attack = torchattacks.CW(standard_model, c=1, steps=100)\n",
    "\n",
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = cw_attack(\n",
    "        images,\n",
    "        labels,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f517309-06c3-4e3d-a556-0904d0d0ee36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd72cd611e104b1bad81ac6a3c19d593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "9280\n"
     ]
    }
   ],
   "source": [
    "cw_attack = torchattacks.CW(standard_model, c=1, steps=500)\n",
    "\n",
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = cw_attack(\n",
    "        images,\n",
    "        labels,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1df1ed7a-217d-494b-93dc-55fc84d16394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d503a62c81c4d77a9f71bc15fcb0626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "9269\n"
     ]
    }
   ],
   "source": [
    "cw_attack = torchattacks.CW(standard_model, c=5, steps=500)\n",
    "\n",
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = cw_attack(\n",
    "        images,\n",
    "        labels,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03bc8ae-d1bb-41ef-a880-49e992a2a073",
   "metadata": {},
   "source": [
    "## PCA-based Detection with a PGD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85b69048-1c3d-473c-a41d-decfdf9fdc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Copy the data and then fit using PCA\n",
    "# First convert to numpy arrays (and make it float)\n",
    "numpyTrainingData = trainSetLoader.dataset.data.astype(\"float32\")\n",
    "# Note you also need to reshape the input data for your sanity\n",
    "reshapedNumpyTrainingData = numpyTrainingData.reshape(\n",
    "    (len(numpyTrainingData), 32 * 32 * 3)\n",
    ")\n",
    "\n",
    "# Then perform PCA on training data to get principal components\n",
    "# Note it should reflect dimension of image, i.e. 28 * 28\n",
    "pca = PCA(n_components=32 * 32 * 3).fit(reshapedNumpyTrainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7c5735-61c9-49b9-bc4d-d53374c96baf",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "309a6ef7-be77-4b08-8f7f-8ec813c963c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Now on clean data check if there are any adversarial samples\n",
    "numpyTestData = testSetLoader.dataset.data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = pgd_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = pgd_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7c5735-61c9-49b9-bc4d-d53374c96baf",
   "metadata": {},
   "source": [
    "#### FGSM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa21b8a8-aeb1-49d9-b2ce-b7f8abd33b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4756a546004fab8ef7f218e9f3a8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = fgsm.fgsm_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        pgd_model,\n",
    "        loss_function,\n",
    "        epsilon=0.75,\n",
    "        alpha=None,\n",
    "        scale=True,\n",
    "        iterations=None,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = pgd_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = pgd_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7c5735-61c9-49b9-bc4d-d53374c96baf",
   "metadata": {},
   "source": [
    "#### PGD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4d2a151-cfaa-475f-8010-c29ef3693686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7749b0ec2daa44739519e3bf557e0e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = pgd.pgd_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        pgd_model,\n",
    "        loss_function,\n",
    "        epsilon=0.75,\n",
    "        alpha=(2 / 255),\n",
    "        scale=True,\n",
    "        iterations=20,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = pgd_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = pgd_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da054166-53ae-481d-81c7-bb7f195d7c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c28d6f79a14f24b005c548c544c9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = pgd.pgd_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        pgd_model,\n",
    "        loss_function,\n",
    "        epsilon=0.15,\n",
    "        alpha=(2 / 255),\n",
    "        scale=True,\n",
    "        iterations=20,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = pgd_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = pgd_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d28f1ce-1a47-4172-9045-9024ec77983c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5085116138d49c28467c836e09519e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = pgd.pgd_attack(\n",
    "        images,\n",
    "        labels,\n",
    "        pgd_model,\n",
    "        loss_function,\n",
    "        epsilon=0.05,\n",
    "        alpha=(2 / 255),\n",
    "        scale=True,\n",
    "        iterations=20,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = pgd_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = pgd_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f84c37-f77b-46a9-a6d2-8c44b172968f",
   "metadata": {},
   "source": [
    "#### $CW_{2}$ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "086f419e-6a65-4bc3-895b-c2d3d155ffc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64a915b803b400f9315d34170a31fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction...\n",
      "Done\n",
      "9271\n"
     ]
    }
   ],
   "source": [
    "cw_attack = torchattacks.CW(standard_model, c=1, steps=100)\n",
    "\n",
    "# Now do the same on adversarial data check if there are any adversarial samples\n",
    "# Use a pretty progress bar to show updates\n",
    "data = []\n",
    "\n",
    "for j, (images, labels) in enumerate(\n",
    "    tqdm(testSetLoader, desc=\"Testing Progress\", leave=False)\n",
    "):\n",
    "    # Cast to proper tensor\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Perturb the images using the attack\n",
    "    perturbed_images = cw_attack(\n",
    "        images,\n",
    "        labels,\n",
    "    )\n",
    "\n",
    "    for perturbed_image in perturbed_images:\n",
    "        data.append(perturbed_image.detach().cpu().numpy())\n",
    "\n",
    "data = np.asarray(data)\n",
    "numpyTestData = data.astype(\"float32\")\n",
    "reshapedNumpyTestData = numpyTestData.reshape((len(numpyTestData), 32 * 32 * 3))\n",
    "\n",
    "# Original predictions on data\n",
    "predictions_base = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "print(\"Original prediction...\")\n",
    "for index in range(len(numpyTestData)):\n",
    "    testTensor = torch.from_numpy(np.reshape(numpyTestData[index], (1, 3, 32, 32))).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "    predictions_base[index] = np.argmax(logits)\n",
    "print(\"Done\")\n",
    "\n",
    "# Transform clean data along principal components\n",
    "transformedTestData = pca.transform(reshapedNumpyTestData)\n",
    "\n",
    "# Decides how many of the least significant coefficients (of components) to perturb\n",
    "num_components = 1000\n",
    "\n",
    "# How many trials to run\n",
    "num_trials = 25\n",
    "\n",
    "# Track results\n",
    "result = np.zeros(len(numpyTestData), dtype=int)\n",
    "\n",
    "# Actual attempts\n",
    "for trial in range(num_trials):\n",
    "    random_noise = np.random.standard_normal(size=num_components)\n",
    "\n",
    "    # Copy the data\n",
    "    transformedTestDataNoisy = np.copy(transformedTestData)\n",
    "\n",
    "    # Update the components with the right data\n",
    "    for index in range(len(numpyTestData)):\n",
    "        transformedTestDataNoisy[index][(32 * 32 * 3 - num_components) :] += (\n",
    "            10 * random_noise\n",
    "        )\n",
    "\n",
    "    # Now calculate the inverse using PCA and the noise\n",
    "    inverseTestDataNoisy = pca.inverse_transform(transformedTestDataNoisy)\n",
    "\n",
    "    # Reshape into image\n",
    "    testDataNoisy = np.reshape(inverseTestDataNoisy, (len(numpyTestData), 3, 32, 32))\n",
    "\n",
    "    # Modified predictions on data\n",
    "    predictions_modified = np.zeros((len(numpyTestData), ))\n",
    "\n",
    "    for index in range(len(testDataNoisy)):\n",
    "        testTensor = torch.from_numpy(\n",
    "            np.reshape(testDataNoisy[index], (1, 3, 32, 32))\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = standard_model(testTensor).detach().cpu().numpy()\n",
    "\n",
    "        predictions_modified[index] = np.argmax(logits)\n",
    "\n",
    "    check = np.not_equal(predictions_modified, predictions_base)\n",
    "    result = np.logical_or(check, result)\n",
    "\n",
    "# Printing\n",
    "print(np.sum(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
